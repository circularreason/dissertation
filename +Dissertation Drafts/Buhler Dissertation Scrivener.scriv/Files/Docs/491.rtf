{\rtf1\ansi\ansicpg1252\cocoartf1348\cocoasubrtf170
{\fonttbl\f0\fnil\fcharset0 Cochin;}
{\colortbl;\red255\green255\blue255;}
\deftab720
\pard\pardeftab720\sl320

\f0\fs24 \cf0 \expnd0\expndtw0\kerning0
Finlay represents the debate over moral realism as taking shape under dialectical pressure from two poles: capturing the moral appearances (especially objective purport) and respecting our understanding of mind and world (especially the \'93scientific worldview\'94). \
\
A response: If the pressure to do \'93justice\'94 to \'93what obvious seems to be the case about the physical world studied by the physical sciences\'94 is reduced, then the pressure from what very obviously seems to be the case about you and me and human nature gets a greater share of the weight. \
\

\b Explanatory Priority Thesis
\b0 \
This supports my
\i  explanatory priority thesis: \
\

\i0 Let A be an educated rational person with a general \'93respect for natural science\'94 as well as a \'93respect\'94 for philosophical reasoning and common sense. Let C be a very particular claim defended by particular natural scientists from a particular natural science, like the claim that \'93Birds descended from dinosaurs\'94 or \'93Water\'92s chemical composition is H20\'94. And let V be some very general claim defended not only by particular ethicists but by many regular non-philosophical people, like \'93It is good to pursue good and avoid evil\'94 (Thomas Aquinas, etc.). \
\

\i \

\i0 For any agent A, unless A believes more certainly a particular empirical claim C more than very particular claim V, A ought first to assume that the evaluative claim V is true when trying to understand the empirical claim C, rather than the other way around. \
\
In short: For any agent A, unless A 
\i more certainly
\i0  believes C than V, A ought to assume V is true when developing explanations of how C is true. The opposite, I argue, would be a ridiculous method and a bad explanatory priority. Switching the relative priority of claims C and V results in a maxim like this: For some agent A, A more certainly believes V than C, yet A assumes C is true in when attempting to explain how V is true. \
\
Now my explanatory priority thesis is similar to an explanatory priority in the vicinity \'97 and I do not wish to conflate to two: Let R be some approximately equally general epistemic claim, like \'93It is rational to follow the evidence.\'94 I am 
\i not 
\i0 necessarily arguing that: For any agent A, unless A more certainly believes R than V, A ought to assume V is true when explaining R. This might be true. But the defenders of naturalistic reductionism do not usually make the 
\i general features 
\i0 of rationality itself the sole object of their adoration.  They equate certain 
\i very particular 
\i0 deliverances from particular natural sciences with rationality itself, and question the rationality of those who would deny, say, that humans have a common ancestor with all other primates, or that the earth is spherical, or that the moon landing actually occurred. \
\
What claim C is known more certainly than V? I have tried on a few (dozen) for myself and none of them do I believe more certainly than that it is bad to be cruel and good to be kind. So, for me, the explanatory priority thesis commends assuming it to be 
\i true 
\i0 that cruelty is bad (construing truth realistically) while I go about trying to explain how it is that neurophysiology and evolutionary biology and astrophysics are  so astonishingly interesting a research programs. \
\
}